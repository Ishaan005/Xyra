"""Add integration layer tables

Revision ID: 49a9af19f3d0
Revises: facc40e7b78d
Create Date: 2025-05-28 17:06:12.655388

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql


# revision identifiers, used by Alembic.
revision: str = '49a9af19f3d0'
down_revision: Union[str, None] = 'facc40e7b78d'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Create integration_connectors table
    op.create_table('integration_connectors',
        sa.Column('id', sa.UUID(), nullable=False),
        sa.Column('organization_id', sa.Integer(), nullable=False),
        sa.Column('connector_id', sa.String(length=255), nullable=False),
        sa.Column('name', sa.String(length=255), nullable=False),
        sa.Column('connector_type', sa.String(length=50), nullable=False),
        sa.Column('config', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
        sa.Column('auth_config', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
        sa.Column('status', sa.String(length=50), nullable=False),
        sa.Column('health_status', sa.String(length=50), nullable=True),
        sa.Column('last_health_check', sa.DateTime(timezone=True), nullable=True),
        sa.Column('metrics', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
        sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
        sa.ForeignKeyConstraint(['organization_id'], ['organization.id'], ),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('connector_id')
    )
    
    # Create integration_webhooks table
    op.create_table('integration_webhooks',
        sa.Column('id', sa.UUID(), nullable=False),
        sa.Column('organization_id', sa.Integer(), nullable=False),
        sa.Column('endpoint_id', sa.String(length=255), nullable=False),
        sa.Column('name', sa.String(length=255), nullable=False),
        sa.Column('url', sa.String(length=1024), nullable=False),
        sa.Column('secret', sa.String(length=255), nullable=False),
        sa.Column('event_types', sa.ARRAY(sa.String(length=100)), nullable=False),
        sa.Column('status', sa.String(length=50), nullable=False),
        sa.Column('retry_config', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column('last_triggered_at', sa.DateTime(timezone=True), nullable=True),
        sa.Column('metrics', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
        sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
        sa.ForeignKeyConstraint(['organization_id'], ['organization.id'], ),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('endpoint_id')
    )
    
    # Create integration_streams table
    op.create_table('integration_streams',
        sa.Column('id', sa.UUID(), nullable=False),
        sa.Column('organization_id', sa.Integer(), nullable=False),
        sa.Column('stream_id', sa.String(length=255), nullable=False),
        sa.Column('name', sa.String(length=255), nullable=False),
        sa.Column('protocol', sa.String(length=50), nullable=False),
        sa.Column('config', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
        sa.Column('status', sa.String(length=50), nullable=False),
        sa.Column('metrics', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
        sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
        sa.ForeignKeyConstraint(['organization_id'], ['organization.id'], ),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('stream_id')
    )
    
    # Create integration_events table
    op.create_table('integration_events',
        sa.Column('id', sa.UUID(), nullable=False),
        sa.Column('organization_id', sa.Integer(), nullable=False),
        sa.Column('agent_id', sa.Integer(), nullable=True),
        sa.Column('source_type', sa.String(length=50), nullable=False),
        sa.Column('source_id', sa.String(length=255), nullable=False),
        sa.Column('event_type', sa.String(length=100), nullable=False),
        sa.Column('external_reference_id', sa.String(length=255), nullable=True),
        sa.Column('timestamp', sa.DateTime(timezone=True), nullable=False),
        sa.Column('raw_data', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
        sa.Column('processed_data', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column('processing_status', sa.String(length=50), nullable=True),
        sa.Column('processing_attempts', sa.Integer(), nullable=True),
        sa.Column('last_processing_error', sa.Text(), nullable=True),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
        sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
        sa.ForeignKeyConstraint(['agent_id'], ['agent.id'], ),
        sa.ForeignKeyConstraint(['organization_id'], ['organization.id'], ),
        sa.PrimaryKeyConstraint('id')
    )
    
    # Create indexes for performance
    op.create_index('idx_integration_events_org_timestamp', 'integration_events', ['organization_id', 'timestamp'])
    op.create_index('idx_integration_events_processing', 'integration_events', ['processing_status', 'created_at'])
    op.create_index('idx_integration_events_agent', 'integration_events', ['agent_id', 'event_type'])
    op.create_index('idx_integration_events_source', 'integration_events', ['source_type', 'source_id'])
    
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Drop indexes
    op.drop_index('idx_integration_events_source', table_name='integration_events')
    op.drop_index('idx_integration_events_agent', table_name='integration_events')
    op.drop_index('idx_integration_events_processing', table_name='integration_events')
    op.drop_index('idx_integration_events_org_timestamp', table_name='integration_events')
    
    # Drop tables (in reverse order due to foreign key constraints)
    op.drop_table('integration_events')
    op.drop_table('integration_streams')
    op.drop_table('integration_webhooks')
    op.drop_table('integration_connectors')
    
    # ### end Alembic commands ###
